

COMMANDS :-
> npm init -y
> npm i express mongoose jsonwebtoken bcryptjs dotenv cookie-parser cookie
> npm i cors (for np in connection between backend and frontend)
  app.js (require cors)


Flow :-

  +-------- ai-message ---------+
  |                             |
  |                             |        generateResponse()
User -----------------------> Server <-------------------------> AI
  |                             |
  |                             | 
  +-------- ai-response --------+
  


R.A.G (Retrival Augmented Generation) :-
LTM (Long Term Memory) and Vector DB comes under RAG Method

**** Define Vector/embeedings :-

> First we need to understand vectors
  vector = array of numbers or float
> ring => []
  conditions for numbers inside vectors 
  n > -1
  n <  1



**** Conversion of string to vector :-

> ring => [-0.009734, 0.443561, -0.934569] (length = 768)
  We convert normal text into vectors

> Total numbers present in the array can be 1024, 3072, 768
  we will be using 768. whenever we will break the string "ring", it will 
  be broken into 768 numbers inside the vector



**** LLM USED IN CONVERSION :-

> Who is president of USA in 2010  ==>  gemini-2.0-flash  ==>  Donald Trump
> We use specific LLMS for converting the text into vector



**** USING VECTOR DB :-

> We can also use MongoDB as vector DB but for now we will use fine Cone
> search Gemini docs
> Models > Embeedings (Vector)
> gemini-embedding-001, we will use this gemini model for conversion of 
  text into vector



**** EXAMPLE VECTOR DB & AI :-

> Example of asking question to AI
  the gap between both the questions is 6 months 
> Date: Jan 2025 :  i have a red car                   =>  [0.123456789, -0.987654321, 0.456789123]
  Date: Aug 2025 :  do you have any idea about my car  =>  [0.123456000, -0.987654333, 0.456789923] 
> When these two texts are converted into vector then the numbers present in 
  these two vectors will have so many numbers common in the trail like
  0.123456789 & 0.123456000
> AI will respond yes you hava a red car



**** VECTOR DB 3D GRAPH :-

> [0.123456789, -0.987654321, 0.456789123]
  [0.123456000, -0.987654333, 0.456789923]
> Plot these 2 points on 3D graph [x, y, z]
> If we have big cluster of so many vector points being plotted on this 3D graph
  then similar words (points as vectors) would be more closer to each other
> Storage    and  Hardware 
  Necessity  and  certain
  Fuels      and  temperature
  corelate with each other, therefore these words vectors will be more closer to each other

> To visualize better search Embeedings Vector website

                             +y    -z
                              |    /
                              |   /
                              |  /
                              | /
                              |/
-x  --------------------------+-------------------------------- +x
                             /|
                            / |
                           /  |
                          /   |
                         /    |
                       -z    -y

> Real life dimensions :
  But vectors in real life have 768 dimensions 
  [0.123, 0.321, -0.122, -0.231, 0.333 ........ 768nth number]
  so we will have 768 axes in the graph and all the values between -1 and +1



**** VECTOR SEARCH & REMEMBERING THE OLD DATA :-

> Date: Jan 2025 :  i have a red car                   =>  [0.123456789, -0.987654321, 0.456789123]
  Date: Aug 2025 :  do you have any idea about my car  =>  [0.123456000, -0.987654333, 0.456789923] 
> When these two vectors will be stored in the 3-D graph then 
  these two points will be very close to each other, because they have similar 
  issue and thats the 'car'
> AI will do Vector search whenever we will ask anything about car
  And will try to find all the vectors near to the car to respond you



**** FINAL IMPLEMENTATION GEMINI DOCS :-

> Search Gemini docs
> Models
> Embeedings
> Generate Embeedings > JavaScript > Code snippet for generate embeedings from normal text



**** TOKENS ?

Input :
  > The car is running on the highway at the speed of 140km/h

Tokenization :
  > Remove filler words and minimize some words like  :  
    is, the, on, of, running -> run
  > Only main woirds are kept : 
    car run highway speed 140km/h
  > Total tokens = ~5 (5 words)
    
Embeeding :
  > car run highway speed 140km/h -----> vector => [0.123, -0.123, 0.333]

Generating response :-
  > Embeedings are given to Gemini 2.0-flash to generate response for user



**** COSTING OF INPUT AND OUTPUT TOKENS :-

> Gemini charges  0.40 USD  for  1M Output tokens  (tokens generated by AI)
  Gemini charges  0.10 USD  for  1M Input tokens   (tokens generated by User)
> Problem :
  So as you go further in a chat conversation, the whole chat history is 
  feeded with each message, which also increases the tokens and pricing
> Solution :
  We only feed previous 5 messages



**** EXAMPLE OF RAG SYSTEM AND 768, 1536, 3072 DIMENSIONS :-

> ring => [-0.123456789, 0.987654321]
> word "ring" is relatable to words like 
  ear, finger, key, phone, wedding, bell
> So the vector of above words will have numbers close to the
  vector of word ring.
> bell => [-0.123456700, 0.987654300]
  ear  => [-0.123456701, 0.987654301]
> On 3D map these words will be very much close
  This can also happen with sentences

> Sentence - 1 : Express is fast framework, its commonly used for building scalable backend
  Sentence - 2 : Can you create an Server with the framework we learn
  Vector of sentence - 1 and sentence - 2 will be very close in Vector DB
> So while responding AI will retrive all points near these two sentences vectors



**** PINE CONE :-

> Pinecone and login 
> Home page > Databse > Indexes > create new Index 
  Name : Default / cohort-chat-gpt
  Dimensions : 768
  Keep other configurations as it is (Configuration, region, cloud service provider)
> click create Index

> Pinecone docs
> QuickStart
> Install an SDK > JavaScript > npm install @pinecone-database/pinecone
> Copy the code snippet from 3. Create an Index > JavaScript
  Paste in VS code > Services > vector.service.js

> Back to Pinecone website
> API keys 
> create a new API key
> Copy paste the API key in .env > vector.service.js code
> Create two functions  1. createMemory and  2. queryMemory  (vector.service.js)  
  => for storing vectors in Pinecone
> Create a function generateVector  (ai.service.js)
  => for generating vectors from users prompt
> import them in socket.server.js


> VS code
  > npx nodemon server.js
> Postman
  > Connect
  > send message 
> Pine cone 
  > Indexes
  > Browser
  > Below records your vector is stored > fetch to see
  > Copy vector values and paste it in notepad to see how it looks



**** VECTOR VALUES STRUCTURE :-
[-0.0229019299, 0.00159309653, 0.0303230658, -0.0678533167, -0.0473020375, -0.0146191698, 0.00112223695, -0.00794144161, -0.011923857, -0.00287591363, -0.038698934, -0.0161875077, -0.0307745412, 0.00299601769, 0.106627919, 0.00714632496, -0.0249009058, -0.00705333287, 0.0221917517, -0.0104254195, -0.0312078092, 0.00731834676, 0.025837576, 0.00911879446, 0.0329597034, 0.00378654432, 0.00679809507, -0.00856763683, 0.00738746068, 0.010939152, 0.00191325729, -0.00582887558, 0.0218224823, -0.000803619856, 0.0277448986, 0.00326662487, 0.00367318885, -0.00814671721, 0.0008330571, 0.010170076, -0.0151684517, -0.0129447971, -0.00651966874, -0.0181571171, 0.0214392766, 0.00955401454, -0.0030474849, -0.00946044084, -0.00769577455, 0.0603191443, -0.0101832654, 0.0142159378, -0.000179025781, -0.187038064, -0.00441655144, 0.0187795106, 0.0149560887, -0.00809112936, 0.00767576555, -0.000873041397, 0.00517327385, 0.0121697588, -0.0190277938, -0.0215850081, -0.00320575549, -0.00589013146, -0.00252472539, 0.0125162546, -0.0256473403, 0.00542721711, 0.00566329947, 0.00540374033, -0.00908815116, -0.00124492799, -0.0102298036, -0.0112347836, 0.0143277664, 0.0217018351, -0.01712754, 0.0212587435, 0.00337905204, 0.0248445794, -0.0201774519, -0.0118971709, -0.022993369, 0.0102764182, -0.0160182212, -0.0235317443, -0.0101268934, -0.0287181027, 0.0311305169, -0.0125164818, 0.0169567764, -0.0121116219, 0.0034225923, 0.0154278707, -0.00348165608, -0.0152390888, -0.00648438, 0.0189179834, -0.0227372739, 0.00122760562, -0.0101003703, 0.000729438616, -0.00638558622, -0.0228979848, -0.00546385907, 0.000881023181, 0.00559526496, 0.0207957774, 0.014505622, 0.00420397939, -0.000625147775, 0.0125184814, 0.00188592286, -0.114863031, 0.00875524525, -0.0026114909, -0.00684904819, 0.00436351309, 0.00316508301, 0.0226025395, -0.00686354516, -0.00908109173, 0.0180063881, 0.0083285654, -0.00615710486, 0.00403962703, 0.00189603353, -0.0101302825, -0.00937629491, -0.00240227254, -0.00129266642, 0.00483919494, -0.015913222, 0.0108310096, -0.0288040843, 0.00189670175, -0.0111660389, -0.0409263819, 0.0135731017, -0.00728854956, -0.00136005739, 0.0203343425, 0.00802454166, 0.0071112616, -0.035984, 0.0148913898, 0.0309716687, -0.00677693356, 0.0200256743, -0.0227403548, -0.0109096281, -0.00262487982, 0.00416422449, -0.0394464508, 0.000708998705, -0.0135652684, 0.00976313651, -0.00440054946, -0.0360099338, 0.00588041265, -0.00851949118, 0.0180767179, -0.00936782546, 0.00970523246, -0.0169957541, -0.0211716518, 0.00977898, 0.000176958856, 0.0166253094, -0.00242427853, -0.0293319821, -0.0016147, 0.0219554808, 0.00288223079, 0.0325591713, -0.00762590673, 0.0330056809, 0.0125645697, -0.0192505438, 0.00738455588, 0.0196494795, 0.00956339203, -0.00144648913, -0.00940946117, -0.0209490117, 0.0140167782, -0.0196161587, -0.00294670835, 0.00732072, -0.000450156949, -0.00721962564, -0.0139993057, 0.00778322387, -0.0203633979, 0.00114290637, 0.0419007167, 0.0191472713, -0.00610247301, -0.00324085448, 0.00622077938, 0.0627473891, 0.0120245768, 0.0296404287, 0.00547772041, 0.016962342, -0.0118188458, 0.0147550954, 0.0167663209, 0.00194004376, -0.0397393294, 0.0341716297, -0.0244814362, -0.00644847145, -0.0121246595, 0.00517066754, 0.0232449, 0.0121840807, 0.0138988234, 0.0481687263, -0.0125358766, 0.00503332261, 0.00910658482, 0.0238509867, -0.0000675705087, -0.000140490258, -0.0462807491, 0.00824195519, -0.0000529835925, -0.00511313556, -0.00312067103, 0.00315191248, -0.0269699972, 0.00918254163, 0.0254102219, 0.00462341448, 0.0103721702, 0.00574654108, -0.014803661, 0.0203289669, -0.0118687423, 0.0118298158, 0.012758201, 0.0368251614, 0.0243787486, 0.00371781271, -0.00145796663, 0.0447844937, -0.0114614833, -0.0178818274, -0.0162061434, 0.0209719744, -0.0181864891, -0.0191869512, -0.00795955583, -0.0435256399, 0.00364493276, 0.0144469142, 0.0194402151, 0.00320841139, -0.0456895158, 0.00181171275, 0.00469551422, 0.00952711143, -0.0102309687, 0.0204719864, -0.0125522632, -0.0230255388, -0.00695017865, 0.0182830933, -0.010965989, -0.025580965, -0.000341897685, -0.00254290528, 0.0369956307, -0.0742374435, 0.0128671769, 0.0203433484, -0.00244367984, -0.0193348248, -0.0127770975, -0.0041263313, -0.0168718863, -0.020876985, 0.000265391951, -0.0286411606, -0.00398609182, 0.00685875444, -0.0118267722, -0.0110879513, 0.00387320179, 0.0279196016, -0.0193254035, 0.0101310993, 0.00761754718, -0.0167790111, -0.0144533208, -0.0122547429, 0.00517704058, 0.00373964338, 0.00213836413, 0.028645413, 0.0525445454, -0.0108149638, -0.000731064938, 0.00789319258, -0.0296090432, 0.0368558951, -0.00324944546, 0.00140486332, 0.0145493252, 0.0152158923, 0.0132034197, 0.0112138819, -0.00781310536, 0.01023209, 0.0173980016, -0.0219154563, -0.00723805744, -0.00768273463, -0.0185492281, 0.0127288466, 0.0241327062, -0.0295036379, -0.0136453975, 0.0000550607037, -0.0038405268, 0.0283472538, -0.0288386736, -0.0160659011, -0.000451121101, 0.0164022073, 0.00672949851, -0.00627454603, -0.00436408306, 0.0198014434, 0.0169350486, 0.0097989589, 0.0179924853, -0.0015801189, -0.0131286243, 0.000279104861, 0.00946396496, -0.00692853332, 0.00915681385, 0.00818067417, -0.0262207072, 0.00424330309, 0.0145314727, 0.00755813299, 0.0451310053, -0.00326886866, -0.0213823766, 0.0119389324, 0.00943497, -0.00350807142, 0.00553265261, 0.0123177208, 0.0190253686, -0.0143180052, -0.00476111053, 0.0326058529, -0.00977825839, 0.012956934, 0.00756195653, 0.0327103212, -0.00362786138, -0.00962968078, 0.000737804, 0.00281975488, 0.0116356295, 0.0141077032, 0.0127576254, -0.00583510194, 0.0137475953, -0.00435293186, 0.0272490829, 0.016487157, -0.000341483101, -0.0265259333, -0.0288727228, -0.00385282026, 0.00125332223, 0.00419104, 0.0486864969, -0.00289031328, 0.00379459024, -0.0127908932, 0.020628266, 0.0102198217, 0.0170136, -0.0138884867, -0.00809573568, 0.0294093564, 0.000676601427, 0.0269972924, -0.0351451188, -0.0181306694, -0.0104943905, 0.0223634336, 0.00800214056, 0.0106913149, -0.0275072269, 0.00455342652, 0.00346391019, 0.00985437073, -0.00697239535, 0.0203365367, -0.0104507217, 0.00258049974, 0.00898845, -0.000102691345, -0.0132278707, 0.0393130109, 0.0121182259, 0.00573962927, 0.0144742755, -0.0118579092, 0.0233765673, 0.0204430241, 0.018172184, -0.0136295008, 0.00134742109, 0.00153803732, -0.018522637, 0.00708828401, -0.00366513501, -0.0100258728, 0.0034262517, 0.00658634864, -0.018601574, -0.0250342283, 0.0018643376, 0.00973123405, -0.0145665463, -0.0105719529, -0.0171577446, 0.00828459393, -0.0105277253, 0.0333717689, 0.0133013315, 0.00481465226, 0.0196339898, -0.0187533032, -0.000765546167, -0.00622308813, -0.0249784514, -0.00539801735, -0.00835562777, 0.0239998475, -0.0131547386, -0.0158082638, -0.0115161417, 0.0284990035, 0.0134363286, 0.00146370346, -0.00246396381, -0.00760371704, -0.013272753, 0.00788713433, 0.0118951537, -0.0199781191, 0.0257040597, 0.017437499, 0.0267480575, 0.000492143445, -0.022865884, -0.0341004394, -0.0224593766, 0.00481598731, 0.0112991156, -0.0233120471, 0.00912795588, -0.0105962567, -0.00399756245, -0.0209265016, 0.0120247919, -0.0109931733, -0.0253827255, 0.0129762106, -0.00372526865, -0.000402871, -0.0137341637, -0.00929170474, 0.00503140315, 0.026047809, 0.0000719497548, -0.00114891096, 0.0168286897, -0.000414625509, 0.0230421238, -0.0133063467, -0.0249015335, -0.0111078778, 0.0201916974, 0.0174000934, 0.000230726859, -0.00835879054, -0.00435947534, 0.0151182869, 0.0202218276, 0.0112932995, -0.0156306289, 0.00254720356, 0.00700993324, 0.0072003263, -0.0178952795, 0.014755331, -0.0150004989, -0.0061528231, 0.0107799871, 0.0136021348, 0.0129903853, 0.00510988198, 0.00415201, 0.0185344312, -0.0105519155, 0.00595743069, 0.00361006917, -0.0124834422, 0.0245506354, 0.00422547152, 0.0141502703, -0.012776, 0.0059487042, 0.0103498353, -0.00804911461, 0.00834250916, 0.0365307294, -0.00669230334, -0.00496664038, 0.0132612791, -0.00148722227, -0.0158749763, 0.00174858852, 0.017810259, 0.0173264723, 0.00199377537, 0.016655894, -0.00437518395, -0.0039765453, -0.0124175269, -0.0241096597, -0.00237446791, -0.0668139905, 0.0220267046, 0.00450463919, -0.00910588261, -0.0000694239206, -0.0325793214, 0.00239583431, -0.00439245626, 0.0160064027, 0.00280806259, 0.0248578, -0.0094045, -0.02284283, 0.00990438554, -0.00205246825, -0.0266095735, -0.0183953065, 0.0109092072, 0.00788384862, -0.0118346829, 0.00171913428, 0.00497944839, 0.0153641589, 0.00376214902, -0.0187460426, -0.0210023131, -0.00106094358, 0.0292497557, 0.000212495346, 0.00430410868, -0.00619489281, -0.0105346534, 0.00994923152, 0.0050667231, 0.0212400872, -0.00376129127, 0.00521505, 0.0229635872, -0.0105785755, 0.0233220868, 0.00284513878, 0.0204885341, -0.00690444652, -0.0017587929, -0.0211892333, 0.00897983555, 0.0215184391, -0.0151602197, -0.0220885128, -0.0260641314, -0.017514186, 0.0158117898, -0.0072772461, 0.0177845564, 0.00187318691, -0.0182657912, 0.0170865562, -0.00790826511, 0.0194589552, 0.0250933412, -0.042564936, -0.00345065119, -0.0273713842, 0.0203238279, -0.00186866557, 0.025538208, 0.00753470184, -0.0193840973, -0.011807261, -0.0112341186, -0.0246788897, 0.00057039439, -0.0414516293, 0.026829198, -0.0232758261, -0.00808249693, 0.0191390757, 0.0312005188, 0.0178625472, -0.0335535295, -0.0356379971, 0.00856267568, -0.0914175063, 0.0039043657, -0.00360101461, 0.00945574418, 0.000537664688, 0.0200387631, -0.0190078989, -0.00427155429, -0.0150451818, 0.0217085518, -0.00801637769, 0.00719473418, 0.00733647775, -0.0146159166, 0.0123024685, 0.00270148413, -0.000750528532, -0.00119746837, 0.0302917, -0.010566012, 0.00512482598, 0.0243879426, -0.00387512147, -0.00371253351, 0.0114534311, -0.00853920914, -0.0104032084, 0.00564885559, 0.022276381, -0.0312541462, -0.0300358627, -0.145863667, 0.00565176271, 0.0179955568, 0.00366276735, -0.00539345806, -0.0246850569, -0.00141976052, 0.0235606153, -0.0138255684, 0.00944699906, -0.00707243057, -0.0143913422, -0.0475439578, 0.011817582, -0.00101068791, 0.122592531, -0.0103036677, -0.00947735924, -0.00640040077, -0.000296051498, -0.0185981821, 0.00472793, -0.0249183085, -0.0303957313, -0.00769678969, 0.0105778798, 0.00390766794, -0.0306054838, 0.00774386898, 0.00930224359, -0.00368383969, 0.00914822239, 0.0147931455, 0.0134970443, 0.0329233967, -0.00980197452, -0.00193293404, -0.00914316438, -0.0132694812, 0.00650292914, 0.0250219945, 0.0101496214, -0.0235173032, 0.0139437029, 0.00321633602, -0.00308334851, -0.00566107733, -0.000563991547, -0.0150784859, 0.0230837148, -0.0324293561, -0.0532642119, -0.0199180655, 0.000888282317, 0.0258206539, -0.0238735434, -0.000702906051, 0.0268279687, -0.0206615292, 0.00164968264, -0.0020517346, -0.0399738438, 0.00335265, -0.00403911, 0.0181705561, 0.0262285098, 0.0396958701, 0.0206563119, -0.00239037257, 0.0201041847, 0.0179645773, -0.00300533767, 0.0204592738, -0.0313472636, 0.0336621106, -0.00250572618, 0.00240964117, 0.0172970071, -0.0214891545, 0.0111303022, -0.0341522209, -0.00200194446, -0.02036299, -0.000350339833, 0.0164401364, -0.00636178767, -0.00431213435, 0.0154275568, -0.0226061586, 0.00379441818, -0.0141190942, 0.0131398859, 0.00366322114, -0.0260749143, -0.0203423705, -0.0266803317, -0.012769796, 0.0197458044, 0.0143551165, 0.00591600128, 0.00134573365, -0.0292529911, 0.0140447197, 0.0128649641, -0.0149260592, -0.0120688844, -0.00388110196, -0.00702864584, 0.0298265386, 0.007817409]



**** QUERY MEMORY RESPONSE :-

Context :-
Q-1 : do you know about express ?
Q-2 : can you create a server with the framework we discussed before ?

Working :-
Now the query memory function will find the previous questions and 
answers records in the Pinecone DB and would relate terms like server.
Relating terms like "server" with prev question terms like "Express"
And heres the what queryMemory function returns :

Next Step (Enhancing AI's response by STM and LTM) :-
Now we will take both STM's (Prev 5 questions stored in MongoDB) 
and LTM's response (queryMemory function's response) and feed it to the
AI (Gemini's prompt)

[
  {
    id: '6922fba3f037c05a5075beb7',
    score: 0.648751855,
    values: [],
    sparseValues: undefined,
    metadata: {
      chat: '691be8d6fe8aeffe7a5a3c73',
      text: 'Do you know about this JS framework called express.js',
      user: '691c17a02dd6284cf354f7c8'
    }
  },
  {
    id: '6922fbaff037c05a5075beba',
    score: 0.605505049,
    values: [],
    sparseValues: undefined,
    metadata: {
      chat: '691be8d6fe8aeffe7a5a3c73',
      text: 'Yes, I do! Express.js is a very popular and widely used Node.js web application framework. I have quite a bit of knowledge about it.\n' +
        '\n' +
        'Specifically, I know about:\n' +
        '\n' +
        '*   **Its Purpose:** Express.js simplifies the process of building web applications and APIs in Node.js. It provides a robust set of features for routing, middleware, templating, and more. It helps organize your application code and makes it easier to handle common web development tasks.\n' +
        '\n' +
        '*   **Key Features:**\n' +
        '    *   **Routing:**  Defining routes to handle different HTTP requests (GET, POST, PUT, DELETE, etc.) based on URL paths.\n' +
        '    *   **Middleware:**  Functions that have access to the request and response objects, allowing you to modify requests, responses, or perform actions like authentication, logging, and error handling.\n' +
        '    *   **Templating Engines:** Support for various templating engines like Pug (formerly Jade), EJS, Handlebars, etc., to dynamically generate HTML pages.\n' +
        '    *   **Static File Serving:**  Easily serving static files like CSS, JavaScript, images, and more.\n' +
        '    *   **Request and Response Handling:** Provides convenient methods for accessing request parameters, headers, and body data, and for sending responses with different status codes, headers, and data formats (JSON, HTML, etc.).\n' +
        '    *   **Middleware Integration:**  Easily integrates with various middleware libraries to extend functionality.\n' + 
        '\n' +
        '*   **Common Use Cases:**\n' +
        '    *   Building RESTful APIs\n' +
        '    *   Creating single-page applications (SPAs)\n' +
        '    *   Developing web applications with server-side rendering\n' +
        '    *   Building mobile backends\n' +
        '\n' +
        '*   **Core Concepts:**\n' +
        '    *   `app`: The Express application object, used to define routes, middleware, and configure the application.\n' +  
        '    *   `request` (req): The request object, containing information about the incoming HTTP request.\n' +
        '    *   `response` (res): The response object, used to send data back to the client.\n' +
        '    *   `next`: A function that passes control to the next middleware function in the chain.\n' +
        '\n' +
        '*   **Example Code (Basic):**\n' +
        '\n' +
        '    ```javascript\n' +
        "    const express = require('express');\n" +
        '    const app = express();\n' +
        '    const port = 3000;\n' +
        '\n' +
        "    app.get('/', (req, res) => {\n" +
        "      res.send('Hello World!');\n" +
        '    });\n' +
        '\n' +
        '    app.listen(port, () => {\n' +
        '      console.log(`Example app listening at http://localhost:${port}`);\n' +
        '    });\n' +
        '    ```\n' +
        '\n' +
        '*   **Why is it popular?**\n' +
        "    *   **Simple and Flexible:**  It's relatively easy to learn and use, and it doesn't enforce a specific architecture, allowing you to structure your application in a way that makes sense for your project.\n" +
        '    *   **Large Community:**  A large and active community provides ample support, tutorials, and pre-built middleware packages.\n' +
        '    *   **Performance:**  Node.js, being event-driven and non-blocking, combined with Express.js, can handle a large number of concurrent connections.\n' +
        '\n' +
        '**Do you have any specific questions about Express.js that I can answer for you? For example, you might ask about:**\n' +
        '\n' +
        '*   How to create a specific type of route\n' +
        '*   How to use middleware for authentication\n' +
        '*   How to connect to a database using Express.js\n' +
        '*   How to deploy an Express.js application\n' +
        '\n' +
        "I'm ready to help in any way I can!\n",
      user: '691c17a02dd6284cf354f7c8'
    }
  },
  {
    id: '6922f7ea3b1f70582b01fb9d',
    score: 0.554166794,
    values: [],
    sparseValues: undefined,
    metadata: {
      chat: '691be8d6fe8aeffe7a5a3c73',
      text: 'Hello! How can I help you today?\n',
      user: '691c17a02dd6284cf354f7c8'
    }
  }
]

Chat History :  [
  { role: 'user', parts: [ [Object] ] },
  { role: 'model', parts: [ [Object] ] },
  { role: 'user', parts: [ [Object] ] },
  { role: 'model', parts: [ [Object] ] },
  { role: 'user', parts: [ [Object] ] },
  { role: 'user', parts: [ [Object] ] }
]

********** CHAT-GPT **********
User Question :  Can you create a server with the framework we have discussed about ?
AI Response :  ```javascript
const express = require('express'); .....



**** TIMELINE :-

1. Save users msg in STM  :  User current msg saved in MongoDB                     
2. Generate User vectors  :  Generate vectors for user message using Gemini model 
3. Save users msg in LTM  :  User current msg saved in Pinecone, .upsert()

4. Retriving LTM  :  Query Pinecone for related memories, .query()  
5. Retriving STM  :  Chat history from MongoDB 

6. Generate response from AI  :  Feeding LTM and STM to AI 
7. Save Model msg in STM      :  Save it in MongoDB
7. Generate Model Vectors     :  Generate vectors for models response using Gemini model
8. Save Model msg in LTM      :  Save it in Pinecone, .upsert()

9. Send Models response to the user  :  Socket.emit()



**** OPTIMIZING THIS TIMELINE :-

If every step takes this much time then pur system is too slow, so by 
optimization we will try to improve the response time 

+--------------------------------------+-------------------------------------------------------------+------------------------------+
| Step                                 | Description                                                 | prev time + execution time   |
+--------------------------------------+-------------------------------------------------------------+------------------------------+
| 1. Save users msg in STM             | User current msg saved in MongoDB                           | ~2s                          |
+--------------------------------------+-------------------------------------------------------------+------------------------------+
| 2. Generate User vectors             | Generate vectors for user message using Gemini model        | ~2s + 5s = 7s                |
+--------------------------------------+-------------------------------------------------------------+------------------------------+
| 3. Save users msg in LTM             | User message saved in Pinecone (.upsert())                  | ~7s + 2s = 9s                |
+--------------------------------------+-------------------------------------------------------------+------------------------------+
| 4. Retriving LTM                     | Query Pinecone for related memories (.query())              | ~9s + 2s                     |
+--------------------------------------+-------------------------------------------------------------+------------------------------+
| 5. Retriving STM                     | Chat history from MongoDB                                   | —                            |
+--------------------------------------+-------------------------------------------------------------+------------------------------+
| 6. Generate response from AI         | Feeding LTM and STM to AI                                   | —                            |
+--------------------------------------+-------------------------------------------------------------+------------------------------+
| 7. Save Model msg in STM             | Save model response in MongoDB                              | —                            |
+--------------------------------------+-------------------------------------------------------------+------------------------------+
| 8. Generate Model Vectors            | Generate vectors for model response using Gemini            | ~3–5s                        |
+--------------------------------------+-------------------------------------------------------------+------------------------------+
| 9. Save Model msg in LTM             | Save model response in Pinecone (.upsert())                 | —                            |
+--------------------------------------+-------------------------------------------------------------+------------------------------+
| 10. Send Models response to the user | socket.emit()                                               | —                            |
+--------------------------------------+-------------------------------------------------------------+------------------------------+


Execution 2 processes parallely (Part - 1) :
> Merging (Executing) =>  Storing user msg in MongoDB (2s)  &&  Generating vectors from user msg (2s + 5s)
  parallely without any hurdle 

  Timing :-
  NOW 2s & 5s will run paralley
  Work done in 5s instead of 7s

  Analogy :-
  We are trying to execute those two processes at the same time which are not dependent on each other.
  Because obviously we cant do those two processes at the same time which are dependent on each other.


Execution 2 processes parallely (Part - 2) :-
> Merging (Executing)  =>  .query  &&  Get chat history from mongoDB
  parallely without any hurdle 

  We are getting chat history from mongoDB and chat history from Pinecone at same time
  messageMOdel.find() and .query() at the same time


Execution 2 processes parallely (Part - 3) :-
> Merging (Executing)  =>  Storing Models msg in MongoDB (2s)  &&  Generating vectors from Models msg (2s + 5s)
  responseMessage storing in MongoDB  &&  responseVector(response)


Execution 2 processes parallely (part - 4) :-
> We will send the response to the user, before storing the response 
  in Pinecone databse and MongoDB, to reduce response time



**** PROMPT FOR SYSTEM INSTRUCTION (ai.service.js file):-

`You are a highly helpful, supportive AI assistant 
who always explains things clearly and accurately. Your personality is 
warm, playful, friendly, and expressive — just like a fun Punjabi friend. 
You speak in a light Punjabi-English mix (Punjabi accent + casual slang), 
but still keep everything understandable and respectful. Your tone should 
make the user feel motivated, energetic, and comfortable. Crack small, 
wholesome jokes, give encouragement, and maintain a chill, positive vibe 
while still staying deeply knowledgeable and useful. Never be rude, never 
insult, and never make the user feel small — always hype them up like a 
supportive Punjabi buddy. And your name is aurora. Use html tags like 
<persona>... </persona> for better understanding (Persona is like behaviour of AI)`



**** FRONTEND PAGES :-

3 pages :-
> Login
> Register
> Chat and create new chat



**** FRONTEND CREATION COMMANDS :-

> npm create vite@latest
> Project name : . 
  enter dot '.' so that frontend folder itself will be used and no new folder will be created inside it.
> Package name : frontend
> React
> JavaScript
> npm run dev



**** REFURBISHMENT IN FRONTEND FILES :-

> index.css : delete index.CSS
> App.jsx : erase everything from App.jsx and 'rafce'
> main.jsx : remove strict mode from main.jsx
> App.css : boiler plate in App.css, just type 'cssbase'



**** FURTHER CMDS :-

> npm i react-router-dom
> npm i react-hook-form
> npm i axios



**** TAILWIND CSS (version 3) SETUP :-

> npm init -y
> npm install -D tailwindcss@3 postcss autoprefixer
> npx tailwindcss init -p

> tailwind.config.js
module.exports = {
  content: [
    "./index.html",
    "./src/**/*.{js,jsx,ts,tsx}"
  ],
  theme: {
    extend: {},
  },
  plugins: [],
}

> src/index.css
@tailwind base;
@tailwind components;
@tailwind utilities;

> main.jsx 
import "./index.css";

> npm run dev





















